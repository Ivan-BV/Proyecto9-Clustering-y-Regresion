# ğŸ“Š Proyecto 9: Clustering y Modelos de RegresiÃ³n

## ğŸ” DescripciÃ³n del Proyecto

Este proyecto se centra en el anÃ¡lisis de datos del comercio global, con el objetivo de mejorar la toma de decisiones en una empresa mediante tÃ©cnicas de **clustering** y **regresiÃ³n**. AsumirÃ¡s el rol de un **cientÃ­fico de datos**, encargado de segmentar clientes y productos y construir modelos de predicciÃ³n adaptados a cada segmento. Esto permitirÃ¡ obtener *insights* especÃ­ficos sobre los factores que influyen en las ventas y beneficios de la compaÃ±Ã­a.

El anÃ¡lisis no solo busca responder preguntas de negocio, sino tambiÃ©n proporcionar recomendaciones accionables que optimicen los procesos y aumenten los beneficios.

## ğŸ¯ Objetivos del proyecto

- **Segmentar clientes y productos** mediante algoritmos de clustering para identificar patrones significativos.
- **Desarrollar modelos de regresiÃ³n** para cada segmento, explicando las relaciones entre las variables clave y permitiendo predecir mÃ©tricas como ventas y beneficios.
- **Proporcionar recomendaciones accionables** basadas en los resultados, orientadas a maximizar la rentabilidad y optimizar las operaciones.

## ğŸ—Œ Estructura del Proyecto

El proyecto estÃ¡ organizado de la siguiente manera:

```bash
â”œâ”€â”€ assets/               # ImÃ¡genes para mostrar en el README
â”‚
â”œâ”€â”€ datos/                # Conjuntos de datos sin procesar y ya procesados
â”‚   â”œâ”€â”€ output/           # Datos procesados y resultados finales
â”‚   â””â”€â”€ raw/              # Datos en bruto (sin procesar)
â”‚
â”œâ”€â”€ modelos/              # Modelos predictivos
â”‚
â”œâ”€â”€ notebooks/            # Notebooks con el contenido y anÃ¡lisis de datos
â”‚
â”œâ”€â”€ src/                  # Scripts para la limpieza y procesamiento de datos
â”‚
â””â”€â”€ README.md             # DescripciÃ³n general del proyecto e instrucciones
```

## ğŸ”§ InstalaciÃ³n y Requisitos

Este proyecto utiliza [Python 3.12](https://docs.python.org/3.12/) y requiere las siguientes librerÃ­as:

- [pandas 2.2.3](https://pandas.pydata.org/docs/)
- [matplotlib 3.9.3](https://matplotlib.org/stable/index.html)
- [seaborn 0.13.2](https://seaborn.pydata.org/tutorial.html)
- [scikit-learn 1.5.2](https://scikit-learn.org/stable/)
- [numpy 2.0.0](https://numpy.org/doc/stable/)

Para instalar las dependencias, puedes ejecutar el siguiente comando dentro de un entorno virtual:

```bash
pip install -r requirements.txt
```

## ğŸ“Š Resultados y Conclusiones

### MÃ©tricas del modelo 1

![Cluster 1](assets/image.png)

- El modelo `random_forest` es el mÃ¡s equilibrado, con un **RÂ² de 0.87 en train** y **0.86 en test**, junto a un error bajo en prueba (MAE de 0.0017). Esto lo convierte en una opciÃ³n muy sÃ³lida y confiable para este cluster.
- Los modelos mÃ¡s complejos como `tree` y `gradient_boosting` presentan signos claros de **sobreajuste**. Aunque logran un **RÂ² muy alto en train** (0.97 y 0.92 respectivamente), su rendimiento en prueba cae drÃ¡sticamente (**RÂ² de -0.90 y 0.40**) y tienen errores mÃ¡s altos, especialmente `tree`.

![Cluster 2](assets/image-1.png)

- Aunque el modelo `random_forest` sigue siendo el mÃ¡s robusto, su desempeÃ±o en prueba es menos consistente, con un **RÂ² de 0.24** y un MAE de 0.0051. AÃºn asÃ­, su error es razonable en comparaciÃ³n con otros modelos.
- El modelo `tree` es el mÃ¡s problemÃ¡tico en este cluster, con un **RÂ² negativo de -0.10** y un RMSE elevado (0.030 en prueba). Esto sugiere que no estÃ¡ manejando bien los datos nuevos y tiene serias dificultades para generalizar.

#### Comparativa de los 2 clusters:

- El Cluster 1 muestra un rendimiento mÃ¡s consistente y menor error global en las mÃ©tricas de prueba, lo que podrÃ­a indicar que sus datos son mÃ¡s fÃ¡ciles de modelar o menos complejos que los del Cluster 2.
- En ambos clusters, `random_forest` se consolida como la mejor opciÃ³n, ofreciendo un buen equilibrio entre entrenamiento y prueba. Por el contrario, `tree` y `gradient_boosting` necesitan ajustes importantes para reducir el sobreajuste.

- Para ambos clusters, el modelo `random_forest` es la opciÃ³n mÃ¡s confiable gracias a su capacidad de mantener un rendimiento balanceado y errores bajos en prueba (por ejemplo, **MAE de 0.0017 en Cluster 1** y **0.0051 en Cluster 2**).
- Modelos mÃ¡s complejos como `tree` y `gradient_boosting` podrÃ­an beneficiarse de ajustes en parÃ¡metros como la profundidad mÃ¡xima o los criterios de divisiÃ³n para mejorar la generalizaciÃ³n y evitar caÃ­das drÃ¡sticas en prueba.
- En general, el Cluster 1 parece ser mÃ¡s fÃ¡cil de modelar, mientras que el Cluster 2 presenta desafÃ­os adicionales que requieren mayor optimizaciÃ³n en los modelos utilizados.

## ğŸ”„ PrÃ³ximos Pasos

- Implementar mejoras en la normalizaciÃ³n de datos y optimizaciÃ³n de hiperparÃ¡metros para los algoritmos de clustering.
- Probar modelos mÃ¡s avanzados, como regresiÃ³n regularizada (Lasso o Ridge) y ensamblados (Gradient Boosting).
- DiseÃ±ar un dashboard interactivo que permita visualizar los resultados y ayudar en la toma de decisiones.

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Si deseas colaborar en este proyecto, por favor abre un pull request o una issue en este repositorio.

